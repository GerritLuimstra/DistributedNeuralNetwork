{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "import matplotlib.pyplot\n",
    "import os\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return (self.wih, self.who)\n",
    "    \n",
    "    def saveModel(self, modelname):\n",
    "        if not os.path.isdir(modelname):\n",
    "            modelname = modelname + str(time.time())\n",
    "            os.makedirs(modelname)\n",
    "        numpy.save(modelname + \"\\\\\" + str(\"wih\"), self.wih)\n",
    "        numpy.save(modelname + \"\\\\\" + str(\"who\"), self.who)\n",
    "        \n",
    "    def loadModel(self, modelname):\n",
    "        self.wih = numpy.load(modelname + \"/wih.npy\")\n",
    "        self.who = numpy.load(modelname + \"/who.npy\")\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02449745  0.01355563 -0.00968997 ... -0.00096125  0.07622864\n",
      "  -0.01608599]\n",
      " [ 0.03895468  0.00034682  0.05793416 ... -0.04231925  0.03358581\n",
      "   0.02291454]\n",
      " [ 0.0735631   0.05794886 -0.02281571 ...  0.04677578 -0.06683916\n",
      "   0.01204523]\n",
      " ...\n",
      " [ 0.03093428 -0.04969668 -0.00190013 ... -0.0416802  -0.05235602\n",
      "   0.03120797]\n",
      " [-0.02460428 -0.0140899  -0.04809533 ... -0.0338522   0.01594332\n",
      "   0.02784381]\n",
      " [ 0.00741507  0.00908753 -0.00311976 ...  0.05589885  0.04503836\n",
      "  -0.01902498]]\n",
      "[[ 0.04128539  0.01094865  0.09758048 ... -0.03842493 -0.05436761\n",
      "   0.00027201]\n",
      " [-0.08486978  0.00794343  0.1207574  ...  0.11501784 -0.01953939\n",
      "  -0.04662072]\n",
      " [-0.0512148   0.0763989  -0.09772571 ...  0.08432414  0.00369496\n",
      "   0.13557444]\n",
      " ...\n",
      " [ 0.0790156   0.10250038 -0.02419265 ... -0.12879906 -0.07933774\n",
      "   0.03248463]\n",
      " [ 0.05652156 -0.0063544  -0.02817128 ...  0.05290802  0.13392405\n",
      "   0.07636539]\n",
      " [-0.13053709  0.12072856  0.08749056 ... -0.04645524  0.02355242\n",
      "   0.02852986]]\n"
     ]
    }
   ],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "# learning rate is\n",
    "learning_rate = 0.1\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "print(n.get_weights()[0])\n",
    "print(n.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "#training_data_file = open(\"MNIST/mnist_train.csv\", 'r')\n",
    "#training_data_list = training_data_file.readlines()\n",
    "#training_data_file.close()\n",
    "#how many time should the data run\n",
    "epochs=5\n",
    "# train the neural network\n",
    "# go through all records in the training data set\n",
    "for e in range(epochs):\n",
    "    break\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # Dividing the raw inputs which are in the range 0-255 by 255 will bring them into the range 0-1. \n",
    "        #We then need to multiply by 0.99 to bring them into the range 0.0 - 0.99. \n",
    "        #We then add 0.01 to shift them up to the desired range 0.01 to 1.00.\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.saveModel(\"models/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "# learning rate is\n",
    "learning_rate = 0.1\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)\n",
    "n.loadModel(\"models/mnist1524245909.173807\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2071b9c3240>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2071b88da90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "#to NOT display the image in a different window\n",
    "%matplotlib inline\n",
    "data_file= open(\"MNIST/mnist_test.csv\", 'r')\n",
    "data_list= data_file.readlines()\n",
    "data_file.close()\n",
    "all_values= data_list[300].split(',')\n",
    "#The [1:] takes all the values in array except the first one,which in out case is the label value.\n",
    "#numpy.asfarray() is a numpy function to convert the text strings into real numbers and to create an array of those numbers\n",
    "#.reshape((28,28)) makes sure the list of number is wrapped around every 28 elements to make a square matrix 28 by 28\n",
    "image_array= numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "#select a greyscale colour palette with cmap=’Greys’ to better show the handwritten characters.\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[0.0009938]\n",
      "1:[0.08119644]\n",
      "2:[0.00583485]\n",
      "3:[0.00263129]\n",
      "4:[0.95674617]\n",
      "5:[0.00010527]\n",
      "6:[0.1277421]\n",
      "7:[0.01658217]\n",
      "8:[1.58728942e-05]\n",
      "9:[0.00127374]\n",
      "I guessed 4 with a value of [0.95674617]\n"
     ]
    }
   ],
   "source": [
    "output = n.query((numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)\n",
    "highest = 0\n",
    "highest_n = 0\n",
    "for index, value in enumerate(output):\n",
    "    print(str(index) + \":\" + str(value))\n",
    "    if value > highest:\n",
    "        highest = value\n",
    "        highest_n = index\n",
    "print(\"I guessed \" + str(highest_n) + \" with a value of \" + str(highest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9732\n"
     ]
    }
   ],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"MNIST/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "# test the neural network\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "#go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    all_values=record.split(',')\n",
    "    correct_label=int(all_values[0])\n",
    "    inputs=(numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    outputs=n.query(inputs)\n",
    "    label = numpy.argmax(outputs)\n",
    "    if label == correct_label:\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass \n",
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
